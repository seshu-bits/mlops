{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Group 39\n",
    "## Team Members\n",
    "1. Akilan K. S. L., 2024AB05003\n",
    "2. Nagendra Prasad Reddy K. V. S., 2024aa05960\n",
    "3. Piramanayagam P., 2024AB05015\n",
    "4. Prathyusha Devi K., 2024aa05182\n",
    "5. Sai Venkata Naga Sesh Kumar Ghanta., 2024aa05989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "\n",
    "def download_heart_disease_dataset(save_dir: str | Path = \"./data\", force_download: bool = False) -> Path:\n",
    "    \"\"\"Download the Heart Disease UCI Dataset and return the data directory.\n",
    "\n",
    "    - Downloads the official UCI Heart Disease archive ZIP\n",
    "    - Extracts it into ``save_dir``\n",
    "    - Returns the path that contains files like ``processed.cleveland.data``\n",
    "    \"\"\"\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # If data directory already has the key files, reuse it\n",
    "    key_file = save_path / \"processed.cleveland.data\"\n",
    "    if key_file.exists() and not force_download:\n",
    "        print(f\"Dataset already present at: {save_path}\")\n",
    "        return save_path\n",
    "\n",
    "    url = \"https://archive.ics.uci.edu/static/public/45/heart+disease.zip\"\n",
    "\n",
    "    try:\n",
    "        print(\"Downloading Heart Disease dataset from UCI Repository...\")\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        print(f\"Extracting dataset to: {save_path}\")\n",
    "        with ZipFile(BytesIO(response.content)) as zip_file:\n",
    "            zip_file.extractall(save_path)\n",
    "\n",
    "        # After extraction, confirm key file(s) exist\n",
    "        if not key_file.exists():\n",
    "            # Some mirrors may have slightly different names; fall back to any *.data file\n",
    "            data_candidates = list(save_path.glob(\"*.data\"))\n",
    "            if not data_candidates:\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Expected 'processed.cleveland.data' or any '*.data' file in {save_path}, \"\n",
    "                    \"but none were found after extraction.\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Warning: 'processed.cleveland.data' not found; using first .data file present.\")\n",
    "\n",
    "        files = list(save_path.glob(\"*\"))\n",
    "        print(f\"\\nDataset directory: {save_path}\")\n",
    "        print(f\"Contains {len(files)} items:\")\n",
    "        for f in sorted(files)[:20]:\n",
    "            print(f\"  - {f.name}\")\n",
    "        if len(files) > 20:\n",
    "            print(f\"  ... and {len(files) - 20} more\")\n",
    "\n",
    "        return save_path\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âœ— Error downloading dataset: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error extracting dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage inside notebook\n",
    "dataset_path = download_heart_disease_dataset()\n",
    "print(f\"\\nDataset is ready at: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_raw_heart_data(data_dir: str | Path = \"./data\") -> pd.DataFrame:\n",
    "    \"\"\"Load the raw Heart Disease dataset from the local directory.\n",
    "\n",
    "    This assumes you've already downloaded the UCI Heart Disease dataset\n",
    "    into ``data_dir`` using ``download_heart_disease_dataset``.\n",
    "\n",
    "    We directly target the standard UCI file ``processed.cleveland.data``\n",
    "    which is present in the archive and is the most commonly used variant.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "\n",
    "    data_file = data_dir / \"processed.cleveland.data\"\n",
    "    if not data_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Expected file '{data_file.name}' not found in {data_dir}. \"\n",
    "            \"Make sure the dataset was downloaded and extracted correctly.\",\n",
    "        )\n",
    "\n",
    "    print(f\"Using data file: {data_file}\")\n",
    "\n",
    "    column_names = [\n",
    "        \"age\",\n",
    "        \"sex\",\n",
    "        \"cp\",\n",
    "        \"trestbps\",\n",
    "        \"chol\",\n",
    "        \"fbs\",\n",
    "        \"restecg\",\n",
    "        \"thalach\",\n",
    "        \"exang\",\n",
    "        \"oldpeak\",\n",
    "        \"slope\",\n",
    "        \"ca\",\n",
    "        \"thal\",\n",
    "        \"target\",\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(data_file, header=None, names=column_names)\n",
    "    print(f\"\\nðŸ“Š Loaded raw dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    # Print statistics of cleanup and pre-processing\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA CLEANUP & PREPROCESSING STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Original data info\n",
    "    print(f\"\\n1. Original Dataset:\")\n",
    "    print(f\"   - Total rows: {df.shape[0]}\")\n",
    "    print(f\"   - Total columns: {df.shape[1]}\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing_markers = (df == \"?\").sum()\n",
    "    total_missing = missing_markers.sum()\n",
    "    if total_missing > 0:\n",
    "        print(f\"\\n2. Missing Values (marked as '?'):\")\n",
    "        print(f\"   - Total missing values: {total_missing}\")\n",
    "        for col in missing_markers[missing_markers > 0].index:\n",
    "            print(f\"   - {col}: {missing_markers[col]} missing\")\n",
    "    \n",
    "    # Target distribution\n",
    "    print(\"\\n3. Target Variable Distribution:\")\n",
    "    print(f\"   - Original target values: {df['target'].unique()}\")\n",
    "    counts_str = df['target'].value_counts().to_string(header=False, index=True)\n",
    "    counts_str = counts_str.replace(\"\\n\", \"\\n     \")\n",
    "    print(\"   - Value counts:\\n\" + counts_str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_and_preprocess_heart_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean the Heart Disease data (missing values + numeric conversion + binary target).\n",
    "\n",
    "    This function DOES NOT perform encoding, scaling or train/test splitting.\n",
    "    It returns a cleaned dataframe with:\n",
    "    - no missing values\n",
    "    - numeric columns converted where possible\n",
    "    - 'target' column binarized (0 = no disease, 1 = disease)\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace UCI missing-value marker '?' with NaN\n",
    "    df = df.replace(\"?\", pd.NA)\n",
    "\n",
    "    # Convert all non-target columns to numeric safely\n",
    "    for col in df.columns:\n",
    "        if col == \"target\":\n",
    "            continue\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except Exception:\n",
    "            # If conversion fails entirely, leave column as-is (will be treated as categorical)\n",
    "            pass\n",
    "\n",
    "    # Drop rows with any missing values (simple strategy for this assignment)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Ensure target is binary: in Cleveland data, values > 0 indicate presence of disease\n",
    "    if \"target\" in df.columns:\n",
    "        df[\"target\"] = (df[\"target\"] > 0).astype(int)\n",
    "    else:\n",
    "        raise KeyError(\"Expected 'target' column in dataframe\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_ml_features(\n",
    "    df: pd.DataFrame,\n",
    "    scaler: StandardScaler | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.Series, StandardScaler]:\n",
    "    \"\"\"Prepare final ML features (encoding + scaling) from a CLEANED dataframe.\n",
    "\n",
    "    Input:\n",
    "    - df: cleaned dataframe (output of clean_and_preprocess_heart_data),\n",
    "           must contain a binary 'target' column.\n",
    "    - scaler: optional existing StandardScaler; if None, a new one is fitted.\n",
    "\n",
    "    Output:\n",
    "    - X: encoded & scaled feature matrix (pandas DataFrame)\n",
    "    - y: target Series\n",
    "    - scaler: fitted StandardScaler\n",
    "    \"\"\"\n",
    "    if \"target\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'target' column in dataframe for feature preparation\")\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\", \"Int64\", \"Float64\"]).columns\n",
    "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    if categorical_cols:\n",
    "        X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Fit scaler if not provided, then transform numeric columns\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "    else:\n",
    "        X[numeric_cols] = scaler.transform(X[numeric_cols])\n",
    "\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "def train_test_split_features(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"Perform a stratified train/test split on prepared features.\"\"\"\n",
    "    return train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Example modular pipeline usage in this notebook\n",
    "try:\n",
    "    # 1. Load raw data\n",
    "    raw_df = load_raw_heart_data(data_dir=Path(dataset_path))\n",
    "\n",
    "    # 2. Clean (handle missing values, numeric conversion, binary target)\n",
    "    cleaned_df = clean_and_preprocess_heart_data(raw_df)\n",
    "\n",
    "    # 3. Prepare final ML features (encoding + scaling)\n",
    "    X, y, scaler = prepare_ml_features(cleaned_df)\n",
    "\n",
    "    # 4. Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split_features(X, y)\n",
    "\n",
    "    print(\"Data cleaning and feature preparation complete.\")\n",
    "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during preprocessing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def perform_eda_heart_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Perform basic EDA with professional visualizations on the Heart Disease data.\n",
    "\n",
    "    Visuals:\n",
    "    - Histograms for key numerical features\n",
    "    - Correlation heatmap\n",
    "    - Class balance bar plot for target\n",
    "    - Box plots of key features by target\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "    # 1. Enhanced Histograms for numerical features with better styling\n",
    "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\", \"Int64\", \"Float64\"]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        n_cols = 3\n",
    "        n_rows = int((len(numeric_cols) + n_cols - 1) / n_cols)\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "        axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "        \n",
    "        for i, col in enumerate(numeric_cols):\n",
    "            sns.histplot(df[col].dropna(), kde=True, bins=30, color=\"#3498db\", \n",
    "                        edgecolor='black', alpha=0.7, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribution of {col.upper()}', fontsize=12, fontweight='bold')\n",
    "            axes[i].set_xlabel(col, fontsize=10)\n",
    "            axes[i].set_ylabel('Frequency', fontsize=10)\n",
    "            axes[i].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Hide extra subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 2. Enhanced Correlation heatmap with annotations\n",
    "    if len(numeric_cols) > 1:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        corr = df[numeric_cols].corr()\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "        sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap=\"RdYlBu_r\", \n",
    "                   center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "        plt.title(\"Correlation Heatmap (Numerical Features)\", fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 3. Enhanced Class balance with percentages\n",
    "    if \"target\" in df.columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        target_counts = df[\"target\"].value_counts().sort_index()\n",
    "        colors = ['#2ecc71', '#e74c3c']\n",
    "        bars = ax.bar(target_counts.index, target_counts.values, color=colors, \n",
    "                     edgecolor='black', linewidth=1.5, alpha=0.8)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            percentage = (height / len(df)) * 100\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height)}\\n({percentage:.1f}%)',\n",
    "                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        ax.set_title(\"Target Variable Distribution\", fontsize=14, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel(\"Target (0 = No Disease, 1 = Disease)\", fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel(\"Count\", fontsize=11, fontweight='bold')\n",
    "        ax.set_xticks(sorted(target_counts.index.tolist()))\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. Additional: Box plots for key features by target (uses seaborn default palette for many classes)\n",
    "    if \"target\" in df.columns and len(numeric_cols) > 1:\n",
    "        key_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "        available_features = [f for f in key_features if f in numeric_cols]\n",
    "        \n",
    "        if available_features:\n",
    "            fig, axes = plt.subplots(1, len(available_features), figsize=(5*len(available_features), 5))\n",
    "            if len(available_features) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, feature in enumerate(available_features):\n",
    "                sns.boxplot(x='target', y=feature, data=df, ax=axes[i])\n",
    "                axes[i].set_title(f'{feature.upper()} by Target', fontsize=11, fontweight='bold')\n",
    "                axes[i].set_xlabel('Target', fontsize=10)\n",
    "                axes[i].set_ylabel(feature, fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## Example EDA usage (call after loading raw_df)\n",
    "perform_eda_heart_data(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"Build and train a Logistic Regression classifier on the training data.\n",
    "\n",
    "    This is the *final* model trained after you have inspected cross-validation results.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(max_iter=1000, n_jobs=-1, solver=\"lbfgs\")\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_random_forest(X_train, y_train, n_estimators: int = 200, random_state: int = 42):\n",
    "    \"\"\"Build and train a Random Forest classifier on the training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train : training data\n",
    "    n_estimators : number of trees\n",
    "    random_state : random seed for reproducibility\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_decision_tree(X_train, y_train, max_depth: int | None = None, random_state: int = 42):\n",
    "    \"\"\"Build and train a Decision Tree classifier on the training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train : training data\n",
    "    max_depth : limit tree depth (None = unlimited)\n",
    "    random_state : random seed for reproducibility\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_classification_model(model, X_train, y_train, X_test, y_test, model_name: str = \"Model\") -> dict:\n",
    "    \"\"\"Evaluate a fitted binary classification model on train and test sets.\n",
    "\n",
    "    Metrics: accuracy, precision, recall, F1-score, ROC-AUC (if available).\n",
    "    Returns a dict of metrics and also prints a brief report.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Some models may not support predict_proba (e.g., some SVM variants); guard accordingly\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    else:\n",
    "        roc_auc = float(\"nan\")\n",
    "\n",
    "    metrics = {\n",
    "        \"train_accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"test_precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"test_recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"test_f1\": f1_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"test_roc_auc\": roc_auc,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n===== {model_name} Performance (Hold-out Test Set) =====\")\n",
    "    print(f\"Train Accuracy: {metrics['train_accuracy']:.3f}\")\n",
    "    print(f\"Test  Accuracy: {metrics['test_accuracy']:.3f}\")\n",
    "    print(f\"Precision:     {metrics['test_precision']:.3f}\")\n",
    "    print(f\"Recall:        {metrics['test_recall']:.3f}\")\n",
    "    print(f\"F1-score:      {metrics['test_f1']:.3f}\")\n",
    "    if not (roc_auc != roc_auc):  # check for NaN\n",
    "        print(f\"ROC-AUC:       {metrics['test_roc_auc']:.3f}\")\n",
    "    print(\"\\nClassification report (test set):\")\n",
    "    print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def cross_validate_models(X, y, cv_splits: int = 5, random_state: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Run cross-validation for Logistic Regression, Random Forest and Decision Tree.\n",
    "\n",
    "    Uses StratifiedKFold and reports mean +/- std for:\n",
    "    - accuracy\n",
    "    - precision\n",
    "    - recall\n",
    "    - F1-score\n",
    "    - ROC-AUC\n",
    "    Returns a pandas DataFrame summarizing model selection metrics.\n",
    "    \"\"\"\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    scoring = {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "        \"f1\": \"f1\",\n",
    "        \"roc_auc\": \"roc_auc\",\n",
    "    }\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1, solver=\"lbfgs\"),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced\",\n",
    "        ),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(\n",
    "            max_depth=None,\n",
    "            random_state=random_state,\n",
    "            class_weight=\"balanced\",\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nRunning {cv_splits}-fold cross-validation for {name}...\")\n",
    "        cv_results = cross_validate(\n",
    "            model, X, y, cv=cv, scoring=scoring, return_train_score=False, n_jobs=-1\n",
    "        )\n",
    "\n",
    "        row = {\"model\": name}\n",
    "        for metric in scoring.keys():\n",
    "            scores = cv_results[f\"test_{metric}\"]\n",
    "            row[f\"{metric}_mean\"] = scores.mean()\n",
    "            row[f\"{metric}_std\"] = scores.std()\n",
    "        rows.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(rows)\n",
    "    print(\"\\n===== Cross-Validation Summary (Model Selection) =====\")\n",
    "    print(results_df.round(3))\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def log_cv_results_to_mlflow(cv_results_df: pd.DataFrame):\n",
    "    \"\"\"Log cross-validation summary table as an MLflow artifact (CSV).\"\"\"\n",
    "    cv_results_df.to_csv(\"cv_results_summary.csv\", index=False)\n",
    "    mlflow.log_artifact(\"cv_results_summary.csv\", artifact_path=\"cv_results\")\n",
    "\n",
    "\n",
    "def log_model_run_to_mlflow(model_name: str, params: dict, metrics: dict):\n",
    "    \"\"\"Log parameters and metrics for a single trained model to MLflow.\"\"\"\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "    for p_name, p_val in params.items():\n",
    "        mlflow.log_param(p_name, p_val)\n",
    "    for m_name, m_val in metrics.items():\n",
    "        mlflow.log_metric(m_name, float(m_val))\n",
    "\n",
    "\n",
    "def log_confusion_matrix_plot(model, X_test, y_test, model_name: str):\n",
    "    \"\"\"Create and log a simple confusion matrix heatmap as an MLflow artifact.\"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plot_path = f\"confusion_matrix_{model_name.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(plot_path, artifact_path=\"plots\")\n",
    "\n",
    "\n",
    "\n",
    "def save_final_model(\n",
    "    model,\n",
    "    model_name: str,\n",
    "    output_dir: str | Path = \"artifacts\",\n",
    "    save_pickle: bool = True,\n",
    "    save_mlflow: bool = True,\n",
    "    save_onnx: bool = False,\n",
    "    X_sample=None,\n",
    "):\n",
    "    \"\"\"Save the final trained model in multiple reusable formats.\n",
    "\n",
    "    - Always supports local pickle and MLflow model logging (if an MLflow run is active)\n",
    "    - Optionally supports ONNX export if ``skl2onnx`` is installed and ``X_sample`` is provided\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    safe_name = model_name.replace(\" \", \"_\").lower()\n",
    "\n",
    "    # 1. Local pickle\n",
    "    if save_pickle:\n",
    "        pkl_path = output_dir / f\"{safe_name}.pkl\"\n",
    "        with open(pkl_path, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"Saved pickle model to: {pkl_path}\")\n",
    "\n",
    "    # 2. MLflow model (if run is active)\n",
    "    if save_mlflow:\n",
    "        try:\n",
    "            import mlflow.sklearn as mls\n",
    "\n",
    "            mls.log_model(model, artifact_path=f\"{safe_name}_mlflow_model\")\n",
    "            print(\n",
    "                f\"Logged model to MLflow under artifact path '{safe_name}_mlflow_model'\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not log model to MLflow: {e}\")\n",
    "\n",
    "    # 3. Optional ONNX export\n",
    "    if save_onnx:\n",
    "        try:\n",
    "            if X_sample is None:\n",
    "                raise ValueError(\"X_sample must be provided to export ONNX model.\")\n",
    "\n",
    "            from skl2onnx import convert_sklearn\n",
    "            from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "            # Take a small numeric sample for schema inference\n",
    "            if hasattr(X_sample, \"values\"):\n",
    "                X_np = X_sample.values.astype(\"float32\")\n",
    "            else:\n",
    "                X_np = np.asarray(X_sample, dtype=\"float32\")\n",
    "\n",
    "            initial_type = [(\"input\", FloatTensorType([None, X_np.shape[1]]))]\n",
    "            onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "            onnx_path = output_dir / f\"{safe_name}.onnx\"\n",
    "            with open(onnx_path, \"wb\") as f:\n",
    "                f.write(onnx_model.SerializeToString())\n",
    "            print(f\"Saved ONNX model to: {onnx_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not export ONNX model: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example model selection, training, evaluation and MLflow logging pipeline\n",
    "try:\n",
    "    mlflow.set_experiment(\"heart_disease_classification\")\n",
    "\n",
    "    # 1. Model selection via cross-validation on the TRAINING data only\n",
    "    cv_results_df = cross_validate_models(X_train, y_train, cv_splits=5, random_state=42)\n",
    "\n",
    "    # Log overall CV summary once at the parent run level\n",
    "    with mlflow.start_run(run_name=\"model_comparison\") as parent_run:\n",
    "        log_cv_results_to_mlflow(cv_results_df)\n",
    "\n",
    "        # 2. For each model, start a nested run to log params, metrics and artifacts\n",
    "        model_configs = [\n",
    "            (\"Logistic Regression\", train_logistic_regression, {\"model_type\": \"log_reg\"}),\n",
    "            (\"Random Forest\", train_random_forest, {\"model_type\": \"random_forest\", \"n_estimators\": 200}),\n",
    "            (\"Decision Tree\", train_decision_tree, {\"model_type\": \"decision_tree\", \"max_depth\": None}),\n",
    "        ]\n",
    "\n",
    "        for model_name, train_fn, base_params in model_configs:\n",
    "            with mlflow.start_run(run_name=model_name, nested=True):\n",
    "                # Train model\n",
    "                model = train_fn(X_train, y_train)\n",
    "\n",
    "                # Evaluate model\n",
    "                metrics = evaluate_classification_model(\n",
    "                    model, X_train, y_train, X_test, y_test, model_name=model_name\n",
    "                )\n",
    "\n",
    "                # Log params & metrics\n",
    "                log_model_run_to_mlflow(model_name, base_params, metrics)\n",
    "\n",
    "                # Log confusion matrix plot\n",
    "                log_confusion_matrix_plot(model, X_test, y_test, model_name)\n",
    "\n",
    "                # Save the trained model in reusable formats (pickle + MLflow, optional ONNX)\n",
    "                save_final_model(\n",
    "                    model,\n",
    "                    model_name=model_name,\n",
    "                    output_dir=\"artifacts\",\n",
    "                    save_pickle=True,\n",
    "                    save_mlflow=True,\n",
    "                    save_onnx=False,\n",
    "                    X_sample=X_train.iloc[:10] if \"X_train\" in globals() else None,\n",
    "                )\n",
    "except Exception as e:\n",
    "    print(f\"Error during model selection/training/evaluation with MLflow: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Start MLflow UI from within the notebook using the current Python interpreter\n",
    "try:\n",
    "    cmd = [sys.executable, \"-m\", \"mlflow\", \"ui\", \"--host\", \"127.0.0.1\", \"--port\", \"5000\"]\n",
    "    print(\"Starting MLflow UI with:\", \" \".join(cmd))\n",
    "    mlflow_ui_process = subprocess.Popen(cmd)\n",
    "    print(\"MLflow UI should now be available at http://127.0.0.1:5000 \",\n",
    "          f\"(PID: {mlflow_ui_process.pid})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error starting MLflow UI: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
